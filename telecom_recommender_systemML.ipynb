{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for phone plan recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra. You have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course). For this classification task, you need to develop a model that will pick the right plan. Since you’ve already performed the data preprocessing step, you can move straight to creating the model.\n",
    "\n",
    "Develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every observation in the dataset contains monthly behavior information about one user. The information given is as follows:\n",
    "\n",
    " - `сalls` — number of calls,\n",
    " - `minutes` — total call duration in minutes,\n",
    " - `messages` — number of text messages,\n",
    " - `mb_used` — Internet traffic used in MB,\n",
    " - `is_ultra` — plan for the current month (Ultra - 1, Smart - 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The objectives of this project is to:\n",
    "- Develop a model that would analyze subscribers' behavior\n",
    "- Build a phone plan recommender system to recommend the right plan based on subscribers' behavior "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    " # Table of contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#open_the_data\">Open the data file and study the general information</a></li>\n",
    "        <li><a href=\"#data_splitting\">Split the source data</a></li>\n",
    "        <li><a href=\"#investigate_models\">Investigate different models quality</a></li>\n",
    "        <li><a href=\"#check_quality\">Check model quality</a></li>\n",
    "        <li><a href=\"#sanity_check\">Sanity check the model</a></li>\n",
    "        <li><a href=\"#overall_conclusion\">Overall conclusion</a></li>\n",
    "    </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"open_the_data\">\n",
    "    <h2>Open the data file and study the general information</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We require the following libraries: *pandas* and *numpy* for data preprocessing and manipulation, *Scikit-Learn* for building our learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project libraries has been successfully been imported!\n"
     ]
    }
   ],
   "source": [
    "# import pandas and numpy for data preprocessing and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import train_test_split to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import machine learning module from the sklearn library\n",
    "from sklearn.tree import DecisionTreeClassifier # import decision tree classifier\n",
    "from sklearn.linear_model import LogisticRegression # import logistic regression \n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest algorithm\n",
    "\n",
    "# import metrics for evaluting model accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Project libraries has been successfully been imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been read correctly!\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "try:\n",
    "    df = pd.read_csv('https://code.s3.yandex.net/datasets/users_behavior.csv')\n",
    "except:\n",
    "    df = pd.read_csv('C:/Users/hotty/Desktop/Practicum by Yandex/Projects/Introduction to Machine Learning/users_behavior.csv')\n",
    "print('Data has been read correctly!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine if columns in file have null values\n",
    "def get_percent_of_na(df, num):\n",
    "    count = 0\n",
    "    df = df.copy()\n",
    "    s = (df.isna().sum() / df.shape[0])\n",
    "    for column, percent in zip(s.index, s.values):\n",
    "        num_of_nulls = df[column].isna().sum()\n",
    "        if num_of_nulls == 0:\n",
    "            continue\n",
    "        else:\n",
    "            count += 1\n",
    "        print('Column {} has {:.{}%} percent of Nulls, and {} of nulls'.format(column, percent, num, num_of_nulls))\n",
    "    if count != 0:\n",
    "        print(\"\\033[1m\" + 'There are {} columns with NA.'.format(count) + \"\\033[0m\")\n",
    "    else:\n",
    "        print()\n",
    "        print(\"\\033[1m\" + 'There are no columns with NA.' + \"\\033[0m\")\n",
    "        \n",
    "# function to display general information about the dataset\n",
    "def get_info(df):\n",
    "    \"\"\"\n",
    "    This function uses the head(), info(), describe(), shape() and duplicated() \n",
    "    methods to display the general information about the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\033[1m\" + '-'*100 + \"\\033[0m\")\n",
    "    print('Head:')\n",
    "    print()\n",
    "    display(df.head())\n",
    "    print('-'*100)\n",
    "    print('Info:')\n",
    "    print()\n",
    "    display(df.info())\n",
    "    print('-'*100)\n",
    "    print('Describe:')\n",
    "    print()\n",
    "    display(df.describe())\n",
    "    print('-'*100)\n",
    "    display(df.describe)\n",
    "    print()\n",
    "    print('Columns with nulls:')\n",
    "    display(get_percent_of_na(df, 4))  # check this out\n",
    "    print('-'*100)\n",
    "    print('Shape:')\n",
    "    print(df.shape)\n",
    "    print('-'*100)\n",
    "    print('Duplicated:')\n",
    "    print(\"\\033[1m\" + 'We have {} duplicated rows.\\n'.format(df.duplicated().sum()) + \"\\033[0m\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General information about the dataframe\n",
      "\u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "Head:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Describe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       calls  minutes  messages   mb_used  is_ultra\n",
       "0      40.0   311.90      83.0  19915.42         0\n",
       "1      85.0   516.75      56.0  22696.96         0\n",
       "2      77.0   467.66      86.0  21060.45         0\n",
       "3     106.0   745.53      81.0   8437.39         1\n",
       "4      66.0   418.74       1.0  14502.75         0\n",
       "...     ...      ...       ...       ...       ...\n",
       "3209  122.0   910.98      20.0  35124.90         1\n",
       "3210   25.0   190.36       0.0   3275.61         0\n",
       "3211   97.0   634.44      70.0  13974.06         0\n",
       "3212   64.0   462.32      90.0  31239.78         0\n",
       "3213   80.0   566.09       6.0  29480.52         1\n",
       "\n",
       "[3214 rows x 5 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with nulls:\n",
      "\n",
      "\u001b[1mThere are no columns with NA.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Shape:\n",
      "(3214, 5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Duplicated:\n",
      "\u001b[1mWe have 0 duplicated rows.\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# study the general information about the dataset \n",
    "print('General information about the dataframe')\n",
    "get_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Since the data have already been preprocessed, we see there are no duplicated rows, or missing values as expected. Now that our data is ready for modeling, let's start by splitting the source dataset into a training set, validation set, and test set using a ratio 3:1:1 or 60% training set, 20% validation set, and 20% testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"data_splitting\">\n",
    "    <h2>Split the source data</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the data into training set, validation set, and test set we use `sklearn.model_selection.train_test_split` twice. First to split train, test and then split train again into validation and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing \n",
    "df_train, df_test = train_test_split(df, test_size=0.20, random_state=12345)\n",
    "\n",
    "# split train data into validation and train \n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.25, random_state=12345) # 0.25 * 0.80 = 0.20 for validation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set now contains 1928 dataset representing 60% of the data\n",
      "The valid set now contains 643 dataset representing 20% of the data\n",
      "The test set now contains 643 dataset representing 20% of the data\n"
     ]
    }
   ],
   "source": [
    "# display the shape of the split dataset\n",
    "print('The train set now contains {}'.format(df_train.shape[0]) + ' dataset representing 60% of the data') \n",
    "print('The valid set now contains {}'.format(df_valid.shape[0]) + ' dataset representing 20% of the data')\n",
    "print('The test set now contains {}'.format(df_test.shape[0]) + ' dataset representing 20% of the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train features : (1928, 4)\n",
      "Train target   : (1928,)\n",
      "Valid features : (643, 4)\n",
      "Valid target   : (643,)\n",
      "Test features  : (643, 4)\n",
      "Test target    : (643,)\n"
     ]
    }
   ],
   "source": [
    "# declare variables for features and target feature\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']\n",
    "\n",
    "print('-'*30)\n",
    "print('Train features :', features_train.shape)\n",
    "print('Train target   :',target_train.shape)\n",
    "print('Valid features :',features_valid.shape)\n",
    "print('Valid target   :',target_valid.shape)\n",
    "print('Test features  :',features_test.shape)\n",
    "print('Test target    :',target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "We have been able to split the data three ways into 60% training set, 20% validation set, and 20% testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"investigate_models\">\n",
    "    <h2>Investigate different models quality</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we proceed to build and investigate different model. Since this is a classification task, we would use the decision tree classifier, logistic regression, and random forestto develop the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the decision tree classifier\n",
    "def decision_tree_classifier(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a decision tree classifier function developed to train \n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets\n",
    "    \"\"\"\n",
    "    # create a loop for max_depth from 1 to 5 \n",
    "    for depth in range(1, 6):\n",
    "        model = DecisionTreeClassifier(random_state=12345, max_depth = depth) # create an instance of a class\n",
    "        model.fit(X_train, y_train) # train the model\n",
    "        train_predictions = model.predict(X_train) # make predictions on train set\n",
    "        predictions_valid = model.predict(X_valid) # make predictions on validation set\n",
    "        print('Max depth and accuracy for decision tree classifier')\n",
    "        print('-'*40)\n",
    "        print(\"\\033[1m\" + 'max_depth = {}'.format(depth) + \"\\033[0m\")\n",
    "        print('Training set:', accuracy_score(y_train, train_predictions))\n",
    "        print('Validation set:', accuracy_score(y_valid, predictions_valid))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth and accuracy for decision tree classifier\n",
      "----------------------------------------\n",
      "\u001b[1mmax_depth = 1\u001b[0m\n",
      "Training set: 0.758298755186722\n",
      "Validation set: 0.7387247278382582\n",
      "\n",
      "Max depth and accuracy for decision tree classifier\n",
      "----------------------------------------\n",
      "\u001b[1mmax_depth = 2\u001b[0m\n",
      "Training set: 0.79201244813278\n",
      "Validation set: 0.7573872472783826\n",
      "\n",
      "Max depth and accuracy for decision tree classifier\n",
      "----------------------------------------\n",
      "\u001b[1mmax_depth = 3\u001b[0m\n",
      "Training set: 0.8117219917012448\n",
      "Validation set: 0.7651632970451011\n",
      "\n",
      "Max depth and accuracy for decision tree classifier\n",
      "----------------------------------------\n",
      "\u001b[1mmax_depth = 4\u001b[0m\n",
      "Training set: 0.8205394190871369\n",
      "Validation set: 0.7636080870917574\n",
      "\n",
      "Max depth and accuracy for decision tree classifier\n",
      "----------------------------------------\n",
      "\u001b[1mmax_depth = 5\u001b[0m\n",
      "Training set: 0.8272821576763485\n",
      "Validation set: 0.7589424572317263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for decision tree classifier\n",
    "decision_tree_classifier(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree classifier can determines the right plan when we run a learning algorithm to train the model to make predictions. We created a loop for `max_depth` hyperparameter from 1 to 6 to see what depth gives us the optimal accuracy. We determined the accuracy of the decision tree classifier at various depth. The depth with the optimum accuracy for training and validation set is depth 4. Notice how the accuracy of the validation test keeps increasing until it gets to `max_depth` of 4. After this depth, the accuracy starts to decline. At `max_depth` of 4, we have an accuracy of 82.05% for the training set, and 76.36% for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the logistic regression model\n",
    "def logistic_regression(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a logistic regression model function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    model.score(X_train, y_train) # check the model's accuracy with score() method\n",
    "    train_predictions = model.predict(X_train) # make predictions on train set\n",
    "    predictions_valid = model.predict(X_valid) # make predictions on validation set\n",
    "    print('Accuracy for logistic regression model')\n",
    "    print('-'*40)\n",
    "    print('Training set:', accuracy_score(y_train, train_predictions))\n",
    "    print('Validation set:', accuracy_score(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regression model\n",
      "----------------------------------------\n",
      "Training set: 0.7028008298755186\n",
      "Validation set: 0.6998444790046656\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for logistic regression model\n",
    "logistic_regression(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the model training is fast, the accuracy is lower. The logistic regression model gave an accuracy of 70.28% for the training set, and about 70% for the validation sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random forest classifier model\n",
    "def random_forest_classifier(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a random forest classifier function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=5)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    model.score(X_train, y_train) # check the model's accuracy with score() method\n",
    "    train_predictions = model.predict(X_train) # make predictions on train set\n",
    "    predictions_valid = model.predict(X_valid) # make predictions on validation set\n",
    "    print('Accuracy for random forest classifier')\n",
    "    print('-'*40)\n",
    "    print('Training set:', accuracy_score(y_train, train_predictions))\n",
    "    print('Validation set:', accuracy_score(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for random forest classifier\n",
      "----------------------------------------\n",
      "Training set: 0.970954356846473\n",
      "Validation set: 0.7620528771384136\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for random forest classifier\n",
    "random_forest_classifier(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tuning hyperparameters for the random forest classifier, we make the `random_state` parameter pseudorandomness static. We also set the number of trees in the forest using `n_estimators=5` hyperparameter. The random forest classifier gave an accuracy of 97.1% for the training data, and 76.20% for the validation data using `n_estimator` of 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "From the investigation of different model quality, we can see that the random forest is the most accurate model with an accuracy of 97.1% for the training data, and 76.20% for the validation data. The logistic regression model was the least accurate model with an accuracy of 70.28% for the training set, and about 70% for the validation sets. We proceed to use the random forest classifier to test prediction on the unseen test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"check_quality\">\n",
    "    <h2>Check model quality</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 0.7807153965785381\n"
     ]
    }
   ],
   "source": [
    "# Testing the random forest classifier model quality\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=5)\n",
    "model.fit(features_train, target_train) # train the model \n",
    "model.score(features_train, target_train) # check the model's accuracy with score() method\n",
    "test_predictions = model.predict(features_test) # make predictions on test set    \n",
    "\n",
    "print('Test set:', accuracy_score(target_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the random forest classifier, we tested the model with the test set to obtain an **accuracy score of 78%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"sanity_check\">\n",
    "    <h2>Sanity check the model</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"overall_conclusion\">\n",
    "    <h2>Overall conclusion</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
